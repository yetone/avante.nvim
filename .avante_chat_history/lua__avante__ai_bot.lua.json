[{"provider": "groq", "timestamp": "2024-08-18 16:21:28", "model": "llama-3.1-70b-versatile", "response": "Replace lines: 272-305\n```lua\n---@type AvanteAiMessageBuilder\nH.make_openrouter_message = function(opts)\n  local user_prompt = base_user_prompt\n    .. \"\\n\\nCODE:\\n\"\n    .. \"```\"\n    .. opts.code_lang\n    .. \"\\n\"\n    .. opts.code_content\n    .. \"\\n```\"\n    .. \"\\n\\nQUESTION:\\n\"\n    .. opts.question\n\n  if opts.selected_code_content ~= nil then\n    user_prompt = base_user_prompt\n      .. \"\\n\\nCODE CONTEXT:\\n\"\n      .. \"```\"\n      .. opts.code_lang\n      .. \"\\n\"\n      .. opts.code_content\n      .. \"\\n```\"\n      .. \"\\n\\nCODE:\\n\"\n      .. \"```\"\n      .. opts.code_lang\n      .. \"\\n\"\n      .. opts.selected_code_content\n      .. \"\\n```\"\n      .. \"\\n\\nQUESTION:\\n\"\n      .. opts.question\n  end\n\n  return {\n    { role = \"system\", content = system_prompt },\n    { role = \"user\", content = user_prompt },\n  }\nend\n\n---@type AvanteAiResponseParser\nH.parse_openrouter_response = function(data_stream, opts)\n  if data_stream:match('\"%[DONE%]\":') then\n    opts.on_complete(nil)\n    return\n  end\n  if data_stream:match('\"delta\":') then\n    local json = vim.json.decode(data_stream)\n    if json.choices and json.choices[1] then\n      local choice = json.choices[1]\n      if choice.finish_reason == \"stop\" then\n        opts.on_complete(nil)\n      elseif choice.delta.content then\n        opts.on_chunk(choice.delta.content)\n      end\n    end\n  end\nend\n\n---@type AvanteCurlArgsBuilder\nH.make_openrouter_curl_args = function(code_opts)\n  return {\n    url = Utils.trim(Config.openrouter.endpoint, { suffix = \"/\" }) .. \"/v1/chat/completions\",\n    headers = {\n      [\"Content-Type\"] = \"application/json\",\n      [\"Authorization\"] = \"Bearer \" .. E.value(\"openrouter\"),\n    },\n    body = {\n      model = Config.openrouter.model,\n      messages = H.make_openrouter_message(code_opts),\n      temperature = Config.openrouter.temperature,\n      max_tokens = Config.openrouter.max_tokens,\n      stream = true,\n    },\n  }\nend\n```\n\nReplace lines: 348-371\n```lua\n---@type AvanteAiMessageBuilder\nH.make_openrouter_message = H.make_openai_message\n\n---@type AvanteAiResponseParser\nH.parse_openrouter_response = H.parse_openai_response\n\n---@type AvanteCurlArgsBuilder\nH.make_openrouter_curl_args = function(code_opts)\n  return {\n    url = Config.openrouter.endpoint\n      .. \"/openai/deployments/\"\n      .. Config.openrouter.deployment\n      .. \"/chat/completions?api-version=\"\n      .. Config.openrouter.api_version,\n    headers = {\n      [\"Content-Type\"] = \"application/json\",\n      [\"api-key\"] = E.value(\"openrouter\"),\n    },\n    body = {\n      messages = H.make_openai_message(code_opts),\n      temperature = Config.openrouter.temperature,\n      max_tokens = Config.openrouter.max_tokens,\n      stream = true,\n    },\n  }\nend\n```\n\nReplace lines: 377-397\n```lua\n---@type AvanteAiMessageBuilder\nH.make_openrouter_message = H.make_openai_message\n\n---@type AvanteAiResponseParser\nH.parse_openrouter_response = H.parse_openai_response\n\n---@type AvanteCurlArgsBuilder\nH.make_openrouter_curl_args = function(code_opts)\n  return {\n    url = Utils.trim(Config.openrouter.endpoint, { suffix = \"/\" }) .. \"/chat/completions\",\n    headers = {\n      [\"Content-Type\"] = \"application/json\",\n      [\"Authorization\"] = \"Bearer \" .. E.value(\"openrouter\"),\n    },\n    body = {\n      model = Config.openrouter.model,\n      messages = H.make_openai_message(code_opts),\n      temperature = Config.openrouter.temperature,\n      max_tokens = Config.openrouter.max_tokens,\n      stream = true,\n    },\n  }\nend\n```\n\nReplace lines: 403-423\n```lua\n---@type AvanteAiMessageBuilder\nH.make_openrouter_message = H.make_openai_message\n\n---@type AvanteAiResponseParser\nH.parse_openrouter_response = H.parse_openai_response\n\n---@type AvanteCurlArgsBuilder\nH.make_openrouter_curl_args = function(code_opts)\n  return {\n    url = Utils.trim(Config.openrouter.endpoint, { suffix = \"/\" }) .. \"/openai/v1/chat/completions\",\n    headers = {\n      [\"Content-Type\"] = \"application/json\",\n      [\"Authorization\"] = \"Bearer \" .. E.value(\"openrouter\"),\n    },\n    body = {\n      model = Config.openrouter.model,\n      messages = H.make_openai_message(code_opts),\n      temperature = Config.openrouter.temperature,\n      max_tokens = Config.openrouter.max_tokens,\n      stream = true,\n    },\n  }\nend\n```\n\nReplace lines: 442-447\n```lua\n---@type AvanteCurlOutput\nlocal spec = H[\"make_\" .. provider .. \"_curl_args\"]({\n  question = question,\n  code_lang = code_lang,\n  code_content = code_content,\n  selected_code_content = selected_content_content,\n})\n```\n\nAdd the following lines to the `E.env` table:\n```lua\nopenrouter = \"OPENROUTER_API_KEY\",\n```\n\nAdd the following lines to the `Config` table:\n```lua\nopenrouter = {\n  endpoint = \"https://api.openrouter.com\",\n  model = \"text-davinci-003\",\n  temperature = 0.7,\n  max_tokens = 2048,\n  api_version = \"2023-06-01\",\n  deployment = \"openrouter-deployment\",\n},\n```", "request": "where else do i need to add OPENROUTER"}]